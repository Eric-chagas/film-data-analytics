{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987330b8",
   "metadata": {},
   "source": [
    "# Fluxo ETL de dados da camada Bronze para camada Silver\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Na camada Bronze, os dados brutos, ou seja, sem tratamento e limpeza de dados estão armazenados no arquivo `TMDB_movie_dataset_v11.csv`. Nessa pipeline, serão realizadas as seguintes operações:\n",
    "\n",
    "- **Limpar e padronizar os dados**: tratar valores nulos, duplicados e NaN;\n",
    "- **Normalizar formatos**: datas, categorias e colunas numéricas;\n",
    "- **Enriquecer ou derivar novas colunas** quando necessário para análises futuras;\n",
    "- **Garantir a qualidade dos dados** antes do carregamento na Silver, que terá dados mais estruturados e prontos para consumo analítico.\n",
    "\n",
    "Na camada Silver ficam armazenados os **dados tratados e consistentes**, que poderão ser utilizados em análises exploratórias e os dashboards no Tableau e PowerBI.  \n",
    "\n",
    "As etapas do fluxo ETL são:\n",
    "\n",
    "1. Carregamento dos dados Bronze (CSV bruto);\n",
    "2. Inspeção e validação inicial das colunas;\n",
    "3. Explosão dos campos compostos em linhas\n",
    "4. Remoção de colunas que não serão usadas;\n",
    "5. Tratamento de valores nulos, vazios, duplicados e NaN;\n",
    "6. Tratamentos e remoção de outliers;\n",
    "7. Armazenamento dos dados tratados na camada Silver em csv;\n",
    "8. Carregamento no banco de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8b546",
   "metadata": {},
   "source": [
    "## Leitura do csv bruto da camada Bronze\n",
    "\n",
    "### Import das bibliotecas, configurações iniciais e inicialização da sessão spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2657be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, arrays_zip, col, trim, ltrim, lit, count, isnan\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType, DateType\n",
    "import time, os, shutil\n",
    "\n",
    "# Inicio sessão spark\n",
    "spark = SparkSession.builder.appName(\"tmdbEtlBronzeToSilver\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9437cd2",
   "metadata": {},
   "source": [
    "### 1. Leitura do csv Bruto\n",
    "\n",
    "Definição do schema do CSV para importação no pyspark dataframe e leitura do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35819946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setando o schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"vote_average\", FloatType(), True),\n",
    "    StructField(\"vote_count\", IntegerType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"release_date\", DateType(), True),\n",
    "    StructField(\"revenue\", IntegerType(), True),\n",
    "    StructField(\"runtime\", IntegerType(), True),\n",
    "    StructField(\"adult\", BooleanType(), True),\n",
    "    StructField(\"backdrop_path\", StringType(), True),\n",
    "    StructField(\"budget\", IntegerType(), True),\n",
    "    StructField(\"homepage\", StringType(), True),\n",
    "    StructField(\"imdb_id\", StringType(), True),\n",
    "    StructField(\"original_language\", StringType(), True),\n",
    "    StructField(\"original_title\", StringType(), True),\n",
    "    StructField(\"overview\", StringType(), True),\n",
    "    StructField(\"popularity\", FloatType(), True),\n",
    "    StructField(\"poster_path\", StringType(), True),\n",
    "    StructField(\"tagline\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True),\n",
    "    StructField(\"production_companies\", StringType(), True),\n",
    "    StructField(\"production_countries\", StringType(), True),\n",
    "    StructField(\"spoken_languages\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ingestão do arquivo\n",
    "csv_path = \"./bronze/TMDB_movie_dataset_v11.csv\" \n",
    "df = spark.read.csv(csv_path, header=True, schema=schema, sep=',', quote='\"', escape='\"')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.summary().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843d7de",
   "metadata": {},
   "source": [
    "### 2. Tratamento de campos compostos\n",
    "\n",
    "No dataset de filmes existem 4 colunas com dados compostos, conforme indicado no [Dicionário de dados](https://github.com/Eric-chagas/film-data-analytics/blob/main/bronze/dicionario_dados.pdf). Essas colunas consistem em arrays com informações separadas por vírgula.\n",
    "\n",
    "Cada linha nessas colunas, serão explodidas em uma ou várias linhas na dataframe principal interligadas pelo ID do filme `movie_id`, abaixo estão os nomes das colunas antes da explosão, e após:\n",
    "\n",
    "1. `genres` -> `genre`\n",
    "2. `production_companies` -> `production_company`\n",
    "3. `production_countries` -> `production_country`\n",
    "4. `spoken_languages` -> `spoken_language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97571ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = df.withColumn(\"genre\", split(col(\"genres\"), \",\")) \\\n",
    "                .withColumn(\"production_company\", split(col(\"production_companies\"), \",\")) \\\n",
    "                .withColumn(\"production_country\", split(col(\"production_countries\"), \",\")) \\\n",
    "                .withColumn(\"spoken_language\", split(col(\"spoken_languages\"), \",\"))\n",
    "\n",
    "# print('Colunas split:')\n",
    "# df_split.select(\"genre\").distinct().show(truncate=False)\n",
    "# df_split.select(\"production_company\").distinct().show(truncate=False)\n",
    "# df_split.select(\"production_country\").distinct().show(truncate=False)\n",
    "# df_split.select(\"spoken_language\").distinct().show(truncate=False)\n",
    "\n",
    "\n",
    "df_exploded = df_split.withColumn(\"genre\", explode(col('genre'))) \\\n",
    "                        .withColumn(\"genre\", trim(col(\"genre\"))) \\\n",
    "                        .withColumn(\"production_company\", explode(col(\"production_company\"))) \\\n",
    "                        .withColumn(\"production_company\", trim(col(\"production_company\"))) \\\n",
    "                        .withColumn(\"production_country\", explode(col(\"production_country\"))) \\\n",
    "                        .withColumn(\"production_country\", trim(col(\"production_country\"))) \\\n",
    "                        .withColumn(\"spoken_language\", explode(col(\"spoken_language\"))) \\\n",
    "                        .withColumn(\"spoken_language\", trim(col(\"spoken_language\"))) \\\n",
    "                            \n",
    "print(\"Colunas exploded:\")             \n",
    "df_exploded.select(\"id\", \"genre\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"production_company\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"production_country\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"spoken_language\").distinct().show(truncate=False)\n",
    "\n",
    "old_cols = [\"genres\", \"production_companies\", \"production_countries\", \"spoken_languages\"]\n",
    "df_exploded = df_split.drop(*old_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b66075",
   "metadata": {},
   "source": [
    "### 3. Remoção das colunas que não serão usadas\n",
    "\n",
    "Existem alguns campos no dataset que não trazem grande valor para a análise realizada nesse trabalho, por tanto, serão removidas. As colunas removidas, em sua maioria consistem em strings com URLs/Paths para imagens ou recursos externos relacionados ao filme, e são elas:\n",
    "\n",
    "1. `backdrop_path`\n",
    "2. `homepage`\n",
    "3. `poster_path`\n",
    "\n",
    "A descrição de cada um pode ser encontrada no [Dicionário de dados](https://github.com/Eric-chagas/film-data-analytics/blob/main/bronze/dicionario_dados.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9edbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_exploded.columns))\n",
    "\n",
    "columns_to_drop = [\"backdrop_path\", \"homepage\", \"poster_path\", \"imdb_id\"]\n",
    "df_refined_cols = df_exploded.drop(*columns_to_drop)\n",
    "\n",
    "# print(len(df_refined_cols.columns))\n",
    "# df_refined_cols.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66f953",
   "metadata": {},
   "source": [
    "### 4. Tratamento de valores nulos, vazios, duplicados e NaN\n",
    "\n",
    "As regras de negócio aplicadas são:\n",
    "\n",
    "1. Remover linhas com `revenue` null/NaN/None\n",
    "2. Remover linhas com `release_date` null/NaN/None/NaT\n",
    "3. Remover colunas 100% nulas caso existam\n",
    "4. Remover linhas em que o título original e o título do filme `original_title` e `title` são ambos vazios\n",
    "5. Remover linhas idênticas caso existam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8097c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.select(\"Revenue\").filter(col(\"Revenue\").isNull()).count())\n",
    "# print(df.select(\"Revenue\").filter(isnan(col(\"Revenue\"))).count())\n",
    "# print(df.select(\"release_date\").filter(col(\"release_date\").isNull()).count())\n",
    "print(f\"df_cols original = {len(df_refined_cols.columns)}\")\n",
    "\n",
    "df_treated_nulls = df_refined_cols.dropna(how=\"all\", subset=df_refined_cols.columns) \n",
    "print(f\"df_cols nulls = {len(df_treated_nulls.columns)}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter(col(\"Revenue\").isNotNull() & ~isnan(col(\"Revenue\")))\n",
    "print(f\"df_rows revenue = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter(col(\"release_date\").isNotNull())\n",
    "print(f\"df_rows date = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter((col(\"original_title\") != \"\") | (col(\"title\") != \"\"))\n",
    "print(f\"df_rows titles = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.distinct()\n",
    "print(f\"df_rows lines = {df_treated_nulls.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742e6ff",
   "metadata": {},
   "source": [
    "### 4. Tratamentos e remoção de outliers\n",
    "\n",
    "Os tratamentos realizados são:\n",
    "\n",
    "1. Remoção de filmes classificados como \"Adulto\"\n",
    "2. Remoção de outliers de popularidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce81ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rows original = 1042016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cols no adult = 929278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 427:>                                                      (0 + 16) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cols no pop outlier = 929276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"df_rows original = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_output = df_treated_nulls.filter(col(\"adult\") == False) \n",
    "print(f\"df_cols no adult = {df_output.count()}\")\n",
    "\n",
    "df_output = df_output.filter(col(\"popularity\") < 2000) \n",
    "print(f\"df_cols no pop outlier = {df_output.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c3b83",
   "metadata": {},
   "source": [
    "### 5. Armazenamento dos dados tratados na camada Silver em csv\n",
    "\n",
    "Os dados tratados são armazenados na camada silver no formato `SILVER_TMDB_movie_dataset_v11_{data_horario}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.tzset()\n",
    "date_formatted = time.strftime(\"%Y%m%d\")\n",
    "time_formatted = time.strftime(\"%H%M%S\")\n",
    "timestamp_str = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(\"Initiating csv save on silver...\")\n",
    "\n",
    "dest_filename = f\"silver/SILVER_TMDB_movie_dataset_v11_{date_formatted}_{time_formatted}\"\n",
    "\n",
    "df_output.selectExpr([f\"CAST({col} AS STRING)\" for col in df_output.columns]).coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").option(\"delimiter\", \",\").csv(dest_filename)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "files = os.listdir(f\"{current_dir}/{dest_filename}\")\n",
    "\n",
    "try:\n",
    "    for f in files:\n",
    "        curr_file = f\"{current_dir}/{dest_filename}/{f}\"\n",
    "        if f.endswith(\".csv\"):\n",
    "            print(f\"achei {curr_file}\")\n",
    "            shutil.copyfile(f\"{curr_file}\", f\"{current_dir}/{dest_filename}.csv\")\n",
    "            os.remove(f\"{curr_file}\")\n",
    "        else:\n",
    "            os.remove(f\"{curr_file}\")\n",
    "            \n",
    "    os.rmdir(f\"{current_dir}/{dest_filename}\")\n",
    "    print(\"Finished.\")\n",
    "\n",
    "except:\n",
    "    print(\"Failed to extract csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58db971",
   "metadata": {},
   "source": [
    "### 6. Inserção dos dados tratados no banco\n",
    "\n",
    "O banco de dados é executado em um container Docker já deve estar rodando e disponível localmente na porta 5432. \n",
    "\n",
    "A conexão com o banco é feita utilizando uma string JDBC e o schema é criado dinâmicamente pelo spark, já de acordo com a estrutura do dataframe de saída `df_output`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
