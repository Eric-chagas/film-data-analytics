{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cbfe97",
   "metadata": {},
   "source": [
    "# Extração de dados do TMDB (The Movie Database)\n",
    "---\n",
    "27/09/2025\n",
    "\n",
    "Este notebook tem como objetivo construir um dataset de filmes utilizando a API do The Movie Database (TMDB). O processo é realizado em duas etapas interligadas:\n",
    "1. A primeira etapa é a extração dos dados de **índice** dos filmes a partir do endpoint `/discover/movie` ou do arquivo Json disponibilizado pelo TMDB e armazenado no repositório em `bronze/movie_ids_10_10_2025.json`. O método usado nesse notebook é ler diretamente do arquivo json.\n",
    "2. A segunda etapa consiste em uma série de requisições para o endpoint `/movie/{movie_id}`, que retorna os dados detalhados de cada filme\n",
    "\n",
    "###### Todos os endpoints utilizados nessa extração estão detalhados na [documentação oficial da API do TMDB](https://developer.themoviedb.org/reference/intro/getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/10 15:13:31 WARN Utils: Your hostname, papercut-vaio, resolves to a loopback address: 127.0.1.1; using 192.168.0.76 instead (on interface wlo1)\n",
      "25/10/10 15:13:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/10 15:13:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode_outer, arrays_zip, col, trim, ltrim, lit, count\n",
    "from os import environ as env\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# API credentials config -----------------------------------------------------------------------------------------------------\n",
    "API_AUTH_CONFIG = {\n",
    "    \"tmdb_api_token\": env.get(\"TMDB_API_TOKEN\") or \"tmdb_api_token_default\",\n",
    "    \"tmdb_api_key\": env.get(\"TMDB_API_KEY\") or \"tmdb_api_key_default\"\n",
    "}\n",
    "\n",
    "# Api rate limit config\n",
    "MAX_REQUESTS_PER_SECOND = 50\n",
    "MIN_TIME_PER_REQUEST = 1.0 / MAX_REQUESTS_PER_SECOND\n",
    "\n",
    "# Pandas configs\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Create spark session\n",
    "spark = SparkSession.builder.appName(\"movieDataIngestion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e470524",
   "metadata": {},
   "source": [
    "### Passo 1. Leitura dos dados de índices de filmes\n",
    "\n",
    "| Componente | Detalhe | Finalidade |\n",
    "| :--- | :--- | :--- |\n",
    "| **Origem** | **`bronze/movie_ids_10_10_2025.json`** | Obtém a lista de filmes que se enquadram em critérios amplos (ex: por popularidade, gênero, ano de lançamento). |\n",
    "| **Output** | Lista de **`id`** (Identificador único do filme) | O ID é o dado chave que será utilizado na próxima etapa. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a36a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read TMDB index json file \n",
    "indexes_file_path = \"bronze/movie_ids_10_10_2025.json\"\n",
    "df_index = spark.read.format(\"json\").option(\"multiline\", \"false\").load(indexes_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04565a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando se não existem filmes adultos. Valores distintos de adult:\n",
      "+-----+\n",
      "|adult|\n",
      "+-----+\n",
      "|false|\n",
      "+-----+\n",
      "\n",
      "+-----+-----+----------------------------------+----------+-----+\n",
      "|adult|id   |original_title                    |popularity|video|\n",
      "+-----+-----+----------------------------------+----------+-----+\n",
      "|false|3924 |Blondie                           |0.435     |false|\n",
      "|false|6124 |Der Mann ohne Namen               |0.5297    |false|\n",
      "|false|8773 |L'Amour à vingt ans               |4.3632    |false|\n",
      "|false|25449|New World Disorder 9: Never Enough|0.0852    |false|\n",
      "|false|31975|Sesame Street: Elmo Loves You!    |0.0214    |true |\n",
      "|false|2    |Ariel                             |1.5549    |false|\n",
      "|false|3    |Varjoja paratiisissa              |2.5798    |false|\n",
      "|false|5    |Four Rooms                        |3.0552    |false|\n",
      "|false|6    |Judgment Night                    |3.8854    |false|\n",
      "|false|8    |Life in Loops (A Megacities RMX)  |1.0294    |false|\n",
      "|false|9    |Sonntag im August                 |0.288     |false|\n",
      "|false|11   |Star Wars                         |14.2586   |false|\n",
      "|false|12   |Finding Nemo                      |13.3766   |false|\n",
      "|false|13   |Forrest Gump                      |16.2693   |false|\n",
      "|false|14   |American Beauty                   |7.36      |false|\n",
      "|false|15   |Citizen Kane                      |3.7593    |false|\n",
      "|false|16   |Dancer in the Dark                |5.5527    |false|\n",
      "|false|17   |The Dark                          |2.2125    |false|\n",
      "|false|18   |Le Cinquième Élément              |14.0736   |false|\n",
      "|false|19   |Metropolis                        |3.2023    |false|\n",
      "+-----+-----+----------------------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "Quantidade de índices de filmes: 1112974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:===================================>                    (10 + 6) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de itens na lista: 1112974\n",
      "[3924, 6124, 8773, 25449, 31975, 2, 3, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Certify no adult movie in dataset\n",
    "print(\"Verificando se não existem filmes adultos. Valores distintos de adult:\")\n",
    "df_index.select(\"adult\").distinct().show(truncate=False)\n",
    "\n",
    "df_index.show(truncate=False)\n",
    "print(f\"Quantidade de índices de filmes: {df_index.count()}\")\n",
    "\n",
    "# Indexes full list for movie requests\n",
    "indexes_full_list = df_index.select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "print(f\"Quantidade de itens na lista: {len(indexes_full_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edd4fc",
   "metadata": {},
   "source": [
    "### Passo 2: Detalhamento Individual dos Filmes \n",
    "\n",
    "| Componente | Detalhe | Finalidade |\n",
    "| :--- | :--- | :--- |\n",
    "| **Endpoint** | **`/movie/{movie_id}`** | Realiza uma consulta específica para cada `id` obtido no Passo 1. |\n",
    "| **Processo** | O código **itera** sobre a lista de IDs extraída. | Garante que cada filme tenha seus dados detalhados coletados. |\n",
    "| **Output Final** | Dados detalhados (`budget`, `revenue`, `runtime`, `production_companies`, etc.). | Cria o *dataset* final para a análise. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current search movie id list from index table response\n",
    "movie_ids = indexes_full_list\n",
    "\n",
    "# Function for single movie request\n",
    "def fetch_film(movie_id):\n",
    "    detail_url = f'https://api.themoviedb.org/3/movie/{movie_id}'\n",
    "    \n",
    "    params = {\n",
    "        \"api_key\": API_AUTH_CONFIG['tmdb_api_key'],\n",
    "        # \"append_to_response\": \"genres\"\n",
    "    }\n",
    "    \n",
    "    movie_detail_response = requests.get(detail_url, params=params)\n",
    "    movie_detail_string = movie_detail_response.content.decode('utf-8')\n",
    "    movie_detail_json = json.loads(movie_detail_string)\n",
    "    \n",
    "    print(f\"Fetched: {movie_detail_json['title']}\")\n",
    "    \n",
    "    return movie_detail_json\n",
    "\n",
    "# Function for parallel movie detail requests\n",
    "def fetch_movies_parallel(movie_ids, max_workers=5):\n",
    "    movie_detail_results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {}\n",
    "        \n",
    "        for movie in movie_ids:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            future = executor.submit(fetch_film, movie)\n",
    "            futures[future] = movie\n",
    "            \n",
    "            time_spent = time.time() - start_time\n",
    "            sleep_time = MIN_TIME_PER_REQUEST - time_spent\n",
    "            \n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                movie_detail_results.append(future.result())\n",
    "            except Exception as e:\n",
    "                mid = futures[future]\n",
    "                print(f\"Erro ao buscar filme {mid}: {e}\")\n",
    "    return movie_detail_results\n",
    "\n",
    "movie_detail_data = fetch_movies_parallel(movie_ids)\n",
    "print(f\"\\nTotal de filmes buscados: {len(movie_detail_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34b897",
   "metadata": {},
   "source": [
    "### Passo 3. Gerar as dataframes finais para a camada bronze\n",
    "\n",
    "Alguns dos campos retornados são arrays de objetos. Esses irão se tornar dataframes separadas, interligadas pelo ID do filme. Em seguida cada uma dessas dataframes, se tornarão um csv para a camada bronze (raw data).\n",
    "\n",
    "Os campos identificados como array são:\n",
    "1. `genres`\n",
    "2. `production_companies`\n",
    "3. `production_countries`\n",
    "4. `spoken_languages`\n",
    "\n",
    "Nesse contexto, os CSVs de saída dessa extração serão:\n",
    "1. movies.csv\n",
    "2. genres.csv\n",
    "3. production_companies.csv\n",
    "4. production_countries.csv\n",
    "5. spoken_languages.csv\n",
    "\n",
    "A chave extrangeira que une cada um desses artefatos, é o ID do filme. Para que isso seja garantido, será adicionada uma coluna `movie_id` em cada nos demais CSVs (com exceção de movies.csv por ser o artefato \"base\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80746814",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_fields = [\"genres\", \"production_companies\", \"production_countries\", \"spoken_languages\"]\n",
    "regular_keys = [key for key in movie_detail_data[0] if key not in array_fields]\n",
    "\n",
    "regular_movie_fields = []\n",
    "\n",
    "for movie in movie_detail_data:\n",
    "    current_movie = {k: v for k, v in movie.items() if k not in array_fields}\n",
    "    regular_movie_fields.append(current_movie)\n",
    "    \n",
    "movie_detail_df = pd.DataFrame(regular_movie_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4d1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_fields_df = {}\n",
    "\n",
    "for key in array_fields:\n",
    "    current_df = pd.json_normalize(\n",
    "        data=movie_detail_data,\n",
    "        record_path=key,\n",
    "        meta=['id'],\n",
    "        record_prefix=f'{key}_'\n",
    "    )\n",
    "    current_df = current_df.rename(columns={'id': 'movie_id', f'{key}_id': 'id'})\n",
    "    array_fields_df[f'{key}_df'] = current_df\n",
    "    \n",
    "    \n",
    "genres_df = array_fields_df['genres_df']\n",
    "production_companies_df = array_fields_df['production_companies_df']\n",
    "production_countries_df = array_fields_df['production_countries_df']\n",
    "spoken_languages_df = array_fields_df['spoken_languages_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7a38b",
   "metadata": {},
   "source": [
    "### Passo 4. Salvar os CSVs na camada bronze\n",
    "\n",
    "Nesse momento existem 5 dataframes, que serão salvas em arquivos CSVs na camada bronze da seguinte forma:\n",
    "\n",
    "|Dataframe|Descrição|Arquivo de saída|\n",
    "|---|---|---|\n",
    "|movie_detail_df|Dataframe principal com os dados de detalhes de filmes|movies.csv|\n",
    "|genres_df|Dataframe com dados de gênero dos filmes|genres.csv|\n",
    "|production_companies_df|Dataframe com dados de produtoras de filmes|production_companies.csv|\n",
    "|production_countries_df|Dataframe com dados de países da produção dos filmes|production_countries.csv|\n",
    "|spoken_languages_df|Dataframe com os idiomas falados para cada filme|spoken_languages.csv|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44772afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_detail_df.to_csv('bronze/movies.csv', index=False)\n",
    "genres_df.to_csv('bronze/genres.csv', index=False)\n",
    "production_companies_df.to_csv('bronze/production_companies.csv', index=False)\n",
    "production_countries_df.to_csv('bronze/production_countries.csv', index=False)\n",
    "spoken_languages_df.to_csv('bronze/spoken_languages.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613ac56",
   "metadata": {},
   "source": [
    "## 3. Ferramentas e Bibliotecas utilizadas\n",
    "\n",
    "| Ferramenta | Uso no Notebook |\n",
    "| :--- | :--- |\n",
    "| **Python `requests`** | Responsável por todas as chamadas HTTP para a API do TMDB. |\n",
    "| **JSON** | Manipulação e *parsing* das respostas da API, que são formatadas em JSON. |\n",
    "| **Pandas** | Estruturação e armazenamento dos dados extraídos em formato DataFrame. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
