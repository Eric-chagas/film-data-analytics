{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987330b8",
   "metadata": {},
   "source": [
    "# Fluxo ETL de dados da camada Bronze para camada Silver\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Na camada Bronze, os dados brutos, ou seja, sem tratamento e limpeza de dados estão armazenados no arquivo `TMDB_movie_dataset_v11.csv`. Nessa pipeline, serão realizadas as seguintes operações:\n",
    "\n",
    "- **Limpar e padronizar os dados**: tratar valores nulos, duplicados e NaN;\n",
    "- **Normalizar formatos**: datas, categorias e colunas numéricas;\n",
    "- **Enriquecer ou derivar novas colunas** quando necessário para análises futuras;\n",
    "- **Garantir a qualidade dos dados** antes do carregamento na Silver, que terá dados mais estruturados e prontos para consumo analítico.\n",
    "\n",
    "Na camada Silver ficam armazenados os **dados tratados e consistentes**, que poderão ser utilizados em análises exploratórias e os dashboards no Tableau e PowerBI.  \n",
    "\n",
    "As etapas do fluxo ETL são:\n",
    "\n",
    "1. Carregamento dos dados Bronze (CSV bruto);\n",
    "2. Inspeção e validação inicial das colunas;\n",
    "3. Explosão dos campos compostos em linhas\n",
    "4. Remoção de colunas que não serão usadas;\n",
    "5. Tratamento de valores nulos, vazios, duplicados e NaN;\n",
    "6. Tratamentos e remoção de outliers;\n",
    "7. Armazenamento dos dados tratados na camada Silver em csv;\n",
    "8. Carregamento no banco de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8b546",
   "metadata": {},
   "source": [
    "## Leitura do csv bruto da camada Bronze\n",
    "\n",
    "### Import das bibliotecas, configurações iniciais e inicialização da sessão spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2657be0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/papercut/Documentos/projects/unb/2025-2/SBD2/film-data-analytics/postgresql-42.7.8.jar\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, arrays_zip, col, trim, ltrim, lit, count, isnan, to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType, DateType\n",
    "import time, os, shutil\n",
    "\n",
    "# Inicio sessão spark\n",
    "jar_path = os.path.abspath(\"../postgresql-42.7.8.jar\")\n",
    "spark = SparkSession.builder.appName(\"tmdbEtlBronzeToSilver\") \\\n",
    "                            .config(\"spark.jars\", jar_path) \\\n",
    "                            .config(\"spark.driver.memory\", \"4g\") \\\n",
    "                            .config(\"spark.executor.memory\", \"4g\") \\\n",
    "                            .getOrCreate()\n",
    "                            \n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(spark.sparkContext._conf.get(\"spark.jars\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9437cd2",
   "metadata": {},
   "source": [
    "### 1. Leitura do csv Bruto\n",
    "\n",
    "Definição do schema do CSV para importação no pyspark dataframe e leitura do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35819946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: float (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- adult: boolean (nullable = true)\n",
      " |-- backdrop_path: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setando o schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"vote_average\", FloatType(), True),\n",
    "    StructField(\"vote_count\", IntegerType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"release_date\", DateType(), True),\n",
    "    StructField(\"revenue\", IntegerType(), True),\n",
    "    StructField(\"runtime\", IntegerType(), True),\n",
    "    StructField(\"adult\", BooleanType(), True),\n",
    "    StructField(\"backdrop_path\", StringType(), True),\n",
    "    StructField(\"budget\", IntegerType(), True),\n",
    "    StructField(\"homepage\", StringType(), True),\n",
    "    StructField(\"imdb_id\", StringType(), True),\n",
    "    StructField(\"original_language\", StringType(), True),\n",
    "    StructField(\"original_title\", StringType(), True),\n",
    "    StructField(\"overview\", StringType(), True),\n",
    "    StructField(\"popularity\", FloatType(), True),\n",
    "    StructField(\"poster_path\", StringType(), True),\n",
    "    StructField(\"tagline\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True),\n",
    "    StructField(\"production_companies\", StringType(), True),\n",
    "    StructField(\"production_countries\", StringType(), True),\n",
    "    StructField(\"spoken_languages\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ingestão do arquivo\n",
    "csv_path = \"../DataLayer/bronze/TMDB_movie_dataset_v11.csv\" \n",
    "df = spark.read.csv(csv_path, header=True, schema=schema, sep=',', quote='\"', escape='\"')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843d7de",
   "metadata": {},
   "source": [
    "### 2. Tratamento de campos compostos\n",
    "\n",
    "No dataset de filmes existem 4 colunas com dados compostos, conforme indicado no [Dicionário de dados](https://github.com/Eric-chagas/film-data-analytics/blob/main/bronze/dicionario_dados.pdf). Essas colunas consistem em arrays com informações separadas por vírgula.\n",
    "\n",
    "Cada linha nessas colunas, serão explodidas em uma ou várias linhas na dataframe principal interligadas pelo ID do filme `movie_id`, abaixo estão os nomes das colunas antes da explosão, e após:\n",
    "\n",
    "1. `genres` -> `genre`\n",
    "2. `production_companies` -> `production_company`\n",
    "3. `production_countries` -> `production_country`\n",
    "4. `spoken_languages` -> `spoken_language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a97571ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas exploded:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|id    |genre          |\n",
      "+------+---------------+\n",
      "|77338 |Drama          |\n",
      "|2062  |Family         |\n",
      "|324857|Adventure      |\n",
      "|273248|Mystery        |\n",
      "|8844  |Family         |\n",
      "|420817|Romance        |\n",
      "|156022|Crime          |\n",
      "|51497 |Crime          |\n",
      "|312221|Action         |\n",
      "|10192 |Fantasy        |\n",
      "|331   |Science Fiction|\n",
      "|44896 |Animation      |\n",
      "|302946|Crime          |\n",
      "|324849|Comedy         |\n",
      "|479455|Comedy         |\n",
      "|59440 |Drama          |\n",
      "|1700  |Thriller       |\n",
      "|941   |Adventure      |\n",
      "|9732  |Animation      |\n",
      "|438695|Family         |\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------+\n",
      "|id    |production_company           |\n",
      "+------+-----------------------------+\n",
      "|752   |DC Comics                    |\n",
      "|64690 |OddLot Entertainment         |\n",
      "|161   |Village Roadshow Pictures    |\n",
      "|76203 |Film4 Productions            |\n",
      "|110415|Opus Pictures                |\n",
      "|454626|Original Film                |\n",
      "|126889|Scott Free Productions       |\n",
      "|339964|UFA                          |\n",
      "|395992|Columbia Pictures            |\n",
      "|43074 |Pascal Pictures              |\n",
      "|399174|American Empirical Pictures  |\n",
      "|431   |Viacom Canada                |\n",
      "|152584|Alcatraz Films               |\n",
      "|6477  |Regency Enterprises          |\n",
      "|526896|Arad Productions             |\n",
      "|4148  |BBC Film                     |\n",
      "|72976 |Amblin Entertainment         |\n",
      "|10330 |Gunn Films                   |\n",
      "|8271  |The Montecito Picture Company|\n",
      "|44048 |Millbrook Farm Productions   |\n",
      "+------+-----------------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------+\n",
      "|id    |production_country      |\n",
      "+------+------------------------+\n",
      "|767   |United States of America|\n",
      "|652   |Malta                   |\n",
      "|70    |United States of America|\n",
      "|198184|South Africa            |\n",
      "|200727|Belgium                 |\n",
      "|331482|United States of America|\n",
      "|9836  |Australia               |\n",
      "|9480  |United States of America|\n",
      "|10830 |United States of America|\n",
      "|301337|Norway                  |\n",
      "|258216|Denmark                 |\n",
      "|71859 |United States of America|\n",
      "|549053|United States of America|\n",
      "|29427 |United States of America|\n",
      "|585083|United States of America|\n",
      "|899112|United States of America|\n",
      "|9531  |United States of America|\n",
      "|592   |United States of America|\n",
      "|746   |Italy                   |\n",
      "|491472|France                  |\n",
      "+------+------------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:=================>                                     (5 + 11) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|id    |spoken_language|\n",
      "+------+---------------+\n",
      "|271110|English        |\n",
      "|127585|Russian        |\n",
      "|393   |Cantonese      |\n",
      "|218   |English        |\n",
      "|85    |English        |\n",
      "|62    |English        |\n",
      "|181812|English        |\n",
      "|59436 |German         |\n",
      "|520763|English        |\n",
      "|311   |English        |\n",
      "|1581  |English        |\n",
      "|428078|English        |\n",
      "|346910|English        |\n",
      "|134374|English        |\n",
      "|72545 |English        |\n",
      "|153518|English        |\n",
      "|419479|English        |\n",
      "|62214 |English        |\n",
      "|1620  |Serbian        |\n",
      "|72113 |English        |\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_split = df.withColumn(\"genre\", split(col(\"genres\"), \",\")) \\\n",
    "                .withColumn(\"production_company\", split(col(\"production_companies\"), \",\")) \\\n",
    "                .withColumn(\"production_country\", split(col(\"production_countries\"), \",\")) \\\n",
    "                .withColumn(\"spoken_language\", split(col(\"spoken_languages\"), \",\"))\n",
    "\n",
    "# print('Colunas split:')\n",
    "# df_split.select(\"genre\").distinct().show(truncate=False)\n",
    "# df_split.select(\"production_company\").distinct().show(truncate=False)\n",
    "# df_split.select(\"production_country\").distinct().show(truncate=False)\n",
    "# df_split.select(\"spoken_language\").distinct().show(truncate=False)\n",
    "\n",
    "\n",
    "df_exploded = df_split.withColumn(\"genre\", explode(col('genre'))) \\\n",
    "                        .withColumn(\"genre\", trim(col(\"genre\"))) \\\n",
    "                        .withColumn(\"production_company\", explode(col(\"production_company\"))) \\\n",
    "                        .withColumn(\"production_company\", trim(col(\"production_company\"))) \\\n",
    "                        .withColumn(\"production_country\", explode(col(\"production_country\"))) \\\n",
    "                        .withColumn(\"production_country\", trim(col(\"production_country\"))) \\\n",
    "                        .withColumn(\"spoken_language\", explode(col(\"spoken_language\"))) \\\n",
    "                        .withColumn(\"spoken_language\", trim(col(\"spoken_language\"))) \\\n",
    "                            \n",
    "print(\"Colunas exploded:\")             \n",
    "df_exploded.select(\"id\", \"genre\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"production_company\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"production_country\").distinct().show(truncate=False)\n",
    "df_exploded.select(\"id\",\"spoken_language\").distinct().show(truncate=False)\n",
    "\n",
    "old_cols = [\"genres\", \"production_companies\", \"production_countries\", \"spoken_languages\"]\n",
    "df_exploded = df_exploded.drop(*old_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b66075",
   "metadata": {},
   "source": [
    "### 3. Remoção das colunas que não serão usadas\n",
    "\n",
    "Existem alguns campos no dataset que não trazem grande valor para a análise realizada nesse trabalho, por tanto, serão removidas. As colunas removidas, em sua maioria consistem em strings com URLs/Paths para imagens ou recursos externos relacionados ao filme, e são elas:\n",
    "\n",
    "1. `backdrop_path`\n",
    "2. `homepage`\n",
    "3. `poster_path`\n",
    "\n",
    "A descrição de cada um pode ser encontrada no [Dicionário de dados](https://github.com/Eric-chagas/film-data-analytics/blob/main/bronze/dicionario_dados.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9edbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_exploded.columns))\n",
    "\n",
    "columns_to_drop = [\"backdrop_path\", \"homepage\", \"poster_path\", \"imdb_id\"]\n",
    "df_refined_cols = df_exploded.drop(*columns_to_drop)\n",
    "\n",
    "# print(len(df_refined_cols.columns))\n",
    "# df_refined_cols.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23a9ddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_overview_null_count = 108504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 152:=============>                                         (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tagline_null_count = 1114059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"df_overview_null_count = {df_refined_cols.select(\"overview\").filter(col(\"overview\").isNull()).count()}\")\n",
    "print(f\"df_tagline_null_count = {df_refined_cols.select(\"tagline\").filter(col(\"tagline\").isNull()).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66f953",
   "metadata": {},
   "source": [
    "### 4. Tratamento de valores nulos, vazios, duplicados e NaN\n",
    "\n",
    "As regras de negócio aplicadas são:\n",
    "\n",
    "1. Remover linhas com `revenue` null/NaN/None\n",
    "2. Remover linhas com `release_date` null/NaN/None/NaT\n",
    "3. Remover colunas 100% nulas caso existam\n",
    "4. Remover linhas em que o título original e o título do filme `original_title` e `title` são ambos vazios\n",
    "5. Remover linhas idênticas caso existam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8097c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cols original = 19\n",
      "df_cols nulls = 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rows revenue = 1753313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rows date = 1701718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rows titles = 1701718\n",
      "df_overview_null_count = 0\n",
      "df_tagline_null_count = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 170:===================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rows lines = 1700013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# print(df.select(\"Revenue\").filter(col(\"Revenue\").isNull()).count())\n",
    "# print(df.select(\"Revenue\").filter(isnan(col(\"Revenue\"))).count())\n",
    "# print(df.select(\"release_date\").filter(col(\"release_date\").isNull()).count())\n",
    "print(f\"df_cols original = {len(df_refined_cols.columns)}\")\n",
    "\n",
    "df_treated_nulls = df_refined_cols.dropna(how=\"all\", subset=df_refined_cols.columns) \n",
    "print(f\"df_cols nulls = {len(df_treated_nulls.columns)}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter(col(\"Revenue\").isNotNull() & ~isnan(col(\"Revenue\")))\n",
    "print(f\"df_rows revenue = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter(col(\"release_date\").isNotNull())\n",
    "print(f\"df_rows date = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.filter((col(\"original_title\") != \"\") | (col(\"title\") != \"\"))\n",
    "print(f\"df_rows titles = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.fillna({\"overview\": \"Film has no overview.\"})\n",
    "print(f\"df_overview_null_count = {df_treated_nulls.select(\"overview\").filter(col(\"overview\").isNull()).count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.fillna({\"tagline\": \"Film has no tagline.\"})\n",
    "print(f\"df_tagline_null_count = {df_treated_nulls.select(\"tagline\").filter(col(\"tagline\").isNull()).count()}\")\n",
    "\n",
    "df_treated_nulls = df_treated_nulls.distinct()\n",
    "print(f\"df_rows lines = {df_treated_nulls.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742e6ff",
   "metadata": {},
   "source": [
    "### 4. Tratamentos e remoção de outliers\n",
    "\n",
    "Os tratamentos realizados são:\n",
    "\n",
    "1. Remoção de filmes classificados como \"Adulto\"\n",
    "2. Remoção de linhas sem votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce81ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF original = 1700013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF no adult = 1689165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 186:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF only voted:  1347484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"DF original = {df_treated_nulls.count()}\")\n",
    "\n",
    "df_output = df_treated_nulls.filter(col(\"adult\") == False) \n",
    "print(f\"DF no adult = {df_output.count()}\")\n",
    "\n",
    "df_output = df_output.filter(col(\"vote_count\") != 0)\n",
    "print('DF only voted: ',df_output.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c3b83",
   "metadata": {},
   "source": [
    "### 5. Armazenamento dos dados tratados na camada Silver em csv\n",
    "\n",
    "Os dados tratados são armazenados na camada silver no formato `SILVER_TMDB_movie_dataset_v11_{data_horario}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3775cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating csv save on silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achei /home/papercut/Documentos/projects/unb/2025-2/SBD2/film-data-analytics/Transformer/../DataLayer/silver/SILVER_TMDB_movie_dataset_v11_20251107_151831/part-00000-5733076d-0ac5-46ba-85df-cb05c77c8d20-c000.csv\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "time.tzset()\n",
    "date_formatted = time.strftime(\"%Y%m%d\")\n",
    "time_formatted = time.strftime(\"%H%M%S\")\n",
    "timestamp_str = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(\"Initiating csv save on silver...\")\n",
    "\n",
    "dest_filename = f\"../DataLayer/silver/SILVER_TMDB_movie_dataset_v11_{date_formatted}_{time_formatted}\"\n",
    "\n",
    "df_output.selectExpr([f\"CAST({col} AS STRING)\" for col in df_output.columns]).coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").option(\"delimiter\", \",\").csv(dest_filename)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "files = os.listdir(f\"{current_dir}/{dest_filename}\")\n",
    "\n",
    "try:\n",
    "    for f in files:\n",
    "        curr_file = f\"{current_dir}/{dest_filename}/{f}\"\n",
    "        if f.endswith(\".csv\"):\n",
    "            print(f\"achei {curr_file}\")\n",
    "            shutil.copyfile(f\"{curr_file}\", f\"{current_dir}/{dest_filename}.csv\")\n",
    "            os.remove(f\"{curr_file}\")\n",
    "        else:\n",
    "            os.remove(f\"{curr_file}\")\n",
    "            \n",
    "    os.rmdir(f\"{current_dir}/{dest_filename}\")\n",
    "    print(\"Finished.\")\n",
    "\n",
    "except:\n",
    "    print(\"Failed to extract csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58db971",
   "metadata": {},
   "source": [
    "### 6. Inserção dos dados tratados no banco\n",
    "\n",
    "O banco de dados é executado em um container Docker já deve estar rodando e disponível localmente na porta 5432. \n",
    "\n",
    "A conexão com o banco é feita utilizando uma string JDBC e o schema é criado dinâmicamente pelo spark, já de acordo com a estrutura do dataframe de saída `df_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final = df_output.withColumn(\"id\", col(\"id\").cast(IntegerType())) \\\n",
    "                    .withColumn(\"title\", col(\"title\").cast(StringType())) \\\n",
    "                    .withColumn(\"vote_average\", col(\"vote_average\").cast(FloatType())) \\\n",
    "                    .withColumn(\"vote_count\", col(\"vote_count\").cast(IntegerType())) \\\n",
    "                    .withColumn(\"status\", col(\"status\").cast(StringType())) \\\n",
    "                    .withColumn(\"release_date\", to_timestamp(col(\"release_date\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                    .withColumn(\"revenue\", col(\"revenue\").cast(IntegerType())) \\\n",
    "                    .withColumn(\"runtime\", col(\"runtime\").cast(IntegerType())) \\\n",
    "                    .withColumn(\"adult\", col(\"adult\").cast(BooleanType())) \\\n",
    "                    .withColumn(\"budget\", col(\"budget\").cast(IntegerType())) \\\n",
    "                    .withColumn(\"original_language\", col(\"original_language\").cast(StringType())) \\\n",
    "                    .withColumn(\"original_title\", col(\"original_title\").cast(StringType())) \\\n",
    "                    .withColumn(\"overview\", col(\"overview\").cast(StringType())) \\\n",
    "                    .withColumn(\"popularity\", col(\"popularity\").cast(FloatType())) \\\n",
    "                    .withColumn(\"tagline\", col(\"tagline\").cast(StringType())) \\\n",
    "                    .withColumn(\"genre\", col(\"genre\").cast(StringType())) \\\n",
    "                    .withColumn(\"production_company\", col(\"production_company\").cast(StringType())) \\\n",
    "                    .withColumn(\"production_country\", col(\"production_country\").cast(StringType())) \\\n",
    "                    .withColumn(\"spoken_language\", col(\"spoken_language\").cast(StringType()))\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"db_user\": os.environ.get(\"DB_USER\") or \"postgres\",\n",
    "    \"db_password\": os.environ.get(\"DB_PASSWORD\") or \"secret\",\n",
    "    \"db_name\": os.environ.get(\"DB_NAME\") or \"postgres\",\n",
    "}\n",
    "jdbc_string = f\"jdbc:postgresql://localhost:5432/{DB_CONFIG[\"db_name\"]}\"\n",
    "table_name = \"lakehouse.film_lakehouse\"\n",
    "df_final.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", jdbc_string) \\\n",
    "  .option(\"dbtable\", table_name) \\\n",
    "  .option(\"user\", DB_CONFIG[\"db_user\"]) \\\n",
    "  .option(\"password\", DB_CONFIG[\"db_password\"]) \\\n",
    "  .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
